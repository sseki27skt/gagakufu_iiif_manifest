#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥æœ¬ã®ä¼çµ±éŸ³æ¥½æ¥½è­œã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèªè­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¸¦æ›¸ããƒ†ã‚­ã‚¹ãƒˆã®è¡Œæ¤œå‡ºã¨æ–‡å­—é ˜åŸŸèªè­˜ã‚’è¡Œã„ã¾ã™
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from scipy import ndimage

def load_image(image_path):
    """ç”»åƒã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {image_path}")
    
    return image

def detect_text_lines(image, expected_lines=3, include_title=False):
    """ç¸¦æ›¸ããƒ†ã‚­ã‚¹ãƒˆã®è¡Œã‚’æ¤œå‡ºã™ã‚‹ï¼ˆä»»æ„ã®è¡Œæ•°ã«å¯¾å¿œï¼‰"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # ãƒã‚¤ã‚ºé™¤å»ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
    denoised = cv2.bilateralFilter(gray, 9, 75, 75)
    
    # äºŒå€¤åŒ–ï¼ˆé©å¿œçš„é–¾å€¤å‡¦ç†ï¼‰
    binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY_INV, 11, 2)
    
    # ç¸¦æ›¸ãæ¥½è­œã®æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå…¨ä½“ï¼‰
    height, width = binary.shape
    horizontal_projection = np.sum(binary, axis=0)
    
    # å…¨ä½“ã®åˆ—æ¤œå‡ºï¼ˆã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚‚å«ã‚€ï¼‰
    from scipy.signal import find_peaks
    from scipy.ndimage import gaussian_filter1d
    
    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    smoothed_projection = gaussian_filter1d(horizontal_projection, sigma=5)
    
    # å…¨ã¦ã®æœ‰æ„ãªãƒ”ãƒ¼ã‚¯ã‚’æ¤œå‡º
    threshold_height = np.max(smoothed_projection) * 0.2
    min_distance = width // (expected_lines + 2)  # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚‚è€ƒæ…®ã—ãŸæœ€å°è·é›¢
    
    peaks, properties = find_peaks(smoothed_projection, 
                                  distance=min_distance, 
                                  height=threshold_height,
                                  prominence=threshold_height * 0.3)
    
    # ãƒ”ãƒ¼ã‚¯ã‹ã‚‰åˆ—å¢ƒç•Œã‚’æ±ºå®š
    all_columns = []
    for peak in peaks:
        # ãƒ”ãƒ¼ã‚¯å‘¨è¾ºã®å¢ƒç•Œã‚’æ¤œå‡º
        left_bound = peak
        right_bound = peak
        threshold = smoothed_projection[peak] * 0.1
        
        # å·¦å´å¢ƒç•Œ
        while left_bound > 0 and smoothed_projection[left_bound] > threshold:
            left_bound -= 1
        
        # å³å´å¢ƒç•Œ
        while right_bound < width - 1 and smoothed_projection[right_bound] > threshold:
            right_bound += 1
        
        # æœ€å°å¹…ãƒã‚§ãƒƒã‚¯
        if right_bound - left_bound > 20:
            all_columns.append((left_bound, right_bound, peak))
    
    # åˆ—ã‚’å³ã‹ã‚‰å·¦ã®é †åºã§ã‚½ãƒ¼ãƒˆï¼ˆç¸¦æ›¸ãã®èª­ã¿é †ï¼‰
    all_columns.sort(key=lambda x: x[2], reverse=True)  # ãƒ”ãƒ¼ã‚¯ä½ç½®ã§ã‚½ãƒ¼ãƒˆ
    
    # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã®æ¤œå‡ºçµæœ
    title_column = None
    
    # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã¨æ¥½è­œæœ¬æ–‡åˆ—ã‚’åˆ†é›¢
    if include_title:
        # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚‚å«ã‚ã¦è§£æ
        if len(all_columns) >= expected_lines + 1:
            title_column = all_columns[0]  # æœ€ã‚‚å³ã®åˆ—ãŒã‚¿ã‚¤ãƒˆãƒ«
            text_columns = all_columns[1:expected_lines+1]  # 2åˆ—ç›®ä»¥é™ãŒæ¥½è­œæœ¬æ–‡
        else:
            # æ¤œå‡ºåˆ—æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
            text_columns = all_columns[:expected_lines]
            
        print(f"å®Œå…¨æ§‹é€ è§£æãƒ¢ãƒ¼ãƒ‰:")
        if title_column:
            print(f"  ã‚¿ã‚¤ãƒˆãƒ«åˆ—: Xåº§æ¨™ {title_column[0]}-{title_column[1]} (å¹…: {title_column[1]-title_column[0]}px)")
        print(f"  æ¥½è­œæœ¬æ–‡åˆ—æ•°: {len(text_columns)}")
    else:
        # æ¥½è­œæœ¬æ–‡ã®ã¿ã‚’è§£æï¼ˆå¾“æ¥ã®å‹•ä½œï¼‰
        if len(all_columns) >= expected_lines:
            # æœ€ã‚‚å³ã®åˆ—ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦é™¤å¤–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            title_column = all_columns[0] if len(all_columns) > expected_lines else None
            
            # æ¥½è­œæœ¬æ–‡ã®åˆ—ã‚’é¸æŠ
            if len(all_columns) > expected_lines:
                # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚’é™¤ã„ã¦ã€æœŸå¾…è¡Œæ•°åˆ†ã‚’é¸æŠ
                text_columns = all_columns[1:expected_lines+1]
            else:
                # å…¨ã¦ã®åˆ—ã‚’æ¥½è­œæœ¬æ–‡ã¨ã—ã¦ä½¿ç”¨
                text_columns = all_columns[:expected_lines]
        else:
            # æ¤œå‡ºã•ã‚ŒãŸåˆ—ãŒå°‘ãªã„å ´åˆã¯å…¨ã¦ã‚’ä½¿ç”¨
            text_columns = all_columns
    
    # ã‚¿ãƒ—ãƒ«ã‹ã‚‰åº§æ¨™ã®ã¿ã‚’æŠ½å‡º
    text_columns = [(start, end) for start, end, _ in text_columns]
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæ¥½è­œæ§‹é€ ã®ç†è§£ã®ãŸã‚ï¼‰
    print(f"æ¤œå‡ºã•ã‚ŒãŸç·åˆ—æ•°: {len(all_columns)}")
    if all_columns:
        rightmost_col = all_columns[0]  # æœ€ã‚‚å³ã®åˆ—ï¼ˆã‚¿ã‚¤ãƒˆãƒ«åˆ—ã®å¯èƒ½æ€§ï¼‰
        print(f"æœ€å³åˆ—ï¼ˆã‚¿ã‚¤ãƒˆãƒ«å€™è£œï¼‰: Xåº§æ¨™ {rightmost_col[0]}-{rightmost_col[1]}")
    print(f"è§£æå¯¾è±¡åˆ—æ•°: {len(text_columns)}")
    
    # ã‚¿ã‚¤ãƒˆãƒ«åˆ—æƒ…å ±ã‚‚è¿”ã™ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
    title_info = {
        'detected': title_column is not None,
        'coordinates': title_column[:2] if title_column else None,
        'included_in_analysis': include_title
    }
    
    return binary, text_columns, horizontal_projection, title_info

def detect_character_regions(binary, text_columns):
    """å„è¡Œå†…ã®æ–‡å­—é ˜åŸŸã‚’æ¤œå‡ºã™ã‚‹ï¼ˆShogaãƒ»Fujiéƒ¨åˆ†ã®ã¿ï¼‰"""
    character_regions = []
    
    for col_idx, (start_col, end_col) in enumerate(text_columns):
        # å„åˆ—å†…ã§ç¸¦æ–¹å‘ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        column_region = binary[:, start_col:end_col]
        vertical_projection = np.sum(column_region, axis=1)
        
        # è¡Œå†…ã®æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆShoga/Fuji/Hyoshiåˆ†æç”¨ï¼‰
        horizontal_projection = np.sum(column_region, axis=0)
        
        # Shogaãƒ”ãƒ¼ã‚¯æ¤œå‡ºï¼ˆæœ€ã‚‚é«˜ã„å¯†åº¦ã®éƒ¨åˆ†ï¼‰
        from scipy.signal import find_peaks
        from scipy.ndimage import gaussian_filter1d
        
        smoothed_h_proj = gaussian_filter1d(horizontal_projection, sigma=2)
        peaks, _ = find_peaks(smoothed_h_proj, 
                             distance=10, 
                             height=np.max(smoothed_h_proj)*0.4)
        
        if len(peaks) > 0:
            # æœ€ã‚‚é«˜ã„ãƒ”ãƒ¼ã‚¯ã‚’Shogaã¨ã—ã¦ç‰¹å®š
            shoga_peak = peaks[np.argmax(smoothed_h_proj[peaks])]
            shoga_center = start_col + shoga_peak
            
            # Shogaé ˜åŸŸã®å¢ƒç•Œæ±ºå®š
            col_width = end_col - start_col
            shoga_left = max(start_col, shoga_center - col_width//6)
            shoga_right = min(end_col, shoga_center + col_width//6)
            
            # Fujié ˜åŸŸï¼ˆShogaã®å·¦å´ï¼‰
            fuji_left = start_col
            fuji_right = shoga_left
            
            # Hyoshié ˜åŸŸï¼ˆShogaã®å³å´ï¼‰- æ–‡å­—èªè­˜å¯¾è±¡å¤–
            hyoshi_left = shoga_right
            hyoshi_right = end_col
            
            print(f"è¡Œ{col_idx+1}ã®æ§‹é€ :")
            print(f"  Fuji: X{fuji_left}-{fuji_right} (å¹…:{fuji_right-fuji_left}px)")
            print(f"  Shoga: X{shoga_left}-{shoga_right} (å¹…:{shoga_right-shoga_left}px)")
            print(f"  Hyoshi: X{hyoshi_left}-{hyoshi_right} (å¹…:{hyoshi_right-hyoshi_left}px)")
            
            # Shogaã¨Fujié ˜åŸŸã§æ–‡å­—æ¤œå‡º
            for region_name, region_start, region_end in [
                ("Shoga", shoga_left, shoga_right),
                ("Fuji", fuji_left, fuji_right)
            ]:
                if region_end > region_start:
                    # è©²å½“é ˜åŸŸã§ã®ç¸¦æ–¹å‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
                    region_binary = binary[:, region_start:region_end]
                    region_v_proj = np.sum(region_binary, axis=1)
                    
                    # æ–‡å­—ã®å¡Šã‚’æ¤œå‡º
                    threshold = np.max(region_v_proj) * 0.15
                    char_rows = []
                    
                    in_char = False
                    start_row = 0
                    
                    for i, density in enumerate(region_v_proj):
                        if density > threshold and not in_char:
                            start_row = i
                            in_char = True
                        elif density <= threshold and in_char:
                            if i - start_row > 8:  # æœ€å°é«˜ã•ãƒ•ã‚£ãƒ«ã‚¿
                                char_rows.append((start_row, i, region_start, region_end, region_name))
                            in_char = False
                    
                    # æœ€å¾Œã®æ–‡å­—ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆ
                    if in_char and len(region_v_proj) - start_row > 8:
                        char_rows.append((start_row, len(region_v_proj), region_start, region_end, region_name))
                    
                    character_regions.extend(char_rows)
        else:
            print(f"è¡Œ{col_idx+1}: Shogaãƒ”ãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    return character_regions

def analyze_layout_structure(text_columns, character_regions, image_shape):
    """æ¥½è­œã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ ã‚’åˆ†æã™ã‚‹ï¼ˆShoga/Fuji/Hyoshiæ§‹é€ å¯¾å¿œï¼‰"""
    height, width = image_shape[:2]
    
    # åˆ—ï¼ˆè¡Œï¼‰ã®çµ±è¨ˆ
    num_lines = len(text_columns)
    line_widths = [end - start for start, end in text_columns]
    avg_line_width = np.mean(line_widths) if line_widths else 0
    
    # æ–‡å­—é ˜åŸŸã®çµ±è¨ˆï¼ˆShogaã¨Fujiã®ã¿ï¼‰
    num_characters = len(character_regions)
    
    # å„è¡Œã®æ–‡å­—æ•°ã¨Shoga/Fujiåˆ†æ
    chars_per_line = []
    shoga_chars_per_line = []
    fuji_chars_per_line = []
    
    for start_col, end_col in text_columns:
        total_chars = 0
        shoga_chars = 0
        fuji_chars = 0
        
        for char_region in character_regions:
            if len(char_region) >= 5:  # æ–°ã—ã„å½¢å¼ï¼ˆregion_nameå«ã‚€ï¼‰
                row_start, row_end, col_start, col_end, region_name = char_region
                if col_start >= start_col and col_end <= end_col:
                    total_chars += 1
                    if region_name == "Shoga":
                        shoga_chars += 1
                    elif region_name == "Fuji":
                        fuji_chars += 1
            else:  # æ—§å½¢å¼ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
                row_start, row_end, col_start, col_end = char_region
                if col_start >= start_col and col_end <= end_col:
                    total_chars += 1
        
        chars_per_line.append(total_chars)
        shoga_chars_per_line.append(shoga_chars)
        fuji_chars_per_line.append(fuji_chars)
    
    # è¡Œé–“éš”ã®è¨ˆç®—
    line_spacing = []
    if len(text_columns) > 1:
        for i in range(len(text_columns) - 1):
            spacing = text_columns[i+1][0] - text_columns[i][1]
            line_spacing.append(spacing)
    
    return {
        'num_lines': num_lines,
        'line_widths': line_widths,
        'avg_line_width': avg_line_width,
        'num_characters': num_characters,
        'chars_per_line': chars_per_line,
        'shoga_chars_per_line': shoga_chars_per_line,
        'fuji_chars_per_line': fuji_chars_per_line,
        'line_spacing': line_spacing,
        'avg_line_spacing': np.mean(line_spacing) if line_spacing else 0
    }

def visualize_layout_analysis(original_image, binary, text_columns, character_regions, horizontal_projection, title_info=None, output_file='score_layout_analysis.png', debug_mode=False, auto_estimate_info=None):
    """æ¥½è­œãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æçµæœã‚’å¯è¦–åŒ–ã™ã‚‹ï¼ˆShoga/Fuji/Hyoshiæ§‹é€ å¯¾å¿œï¼‰"""
    # çµæœç”¨ã®ç”»åƒã‚’ä½œæˆ
    result_image = original_image.copy()
    
    # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚’æç”»ï¼ˆã‚ã‚Œã°ï¼‰
    if title_info and title_info['detected'] and title_info['coordinates']:
        start_col, end_col = title_info['coordinates']
        # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã¯ç‰¹åˆ¥ãªè‰²ï¼ˆé‡‘è‰²ï¼‰ã§æç”»
        cv2.rectangle(result_image, (start_col, 0), (end_col, original_image.shape[0]), (0, 215, 255), 3)
        cv2.putText(result_image, 'Title', (start_col, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 215, 255), 2)
    
    # ãƒ†ã‚­ã‚¹ãƒˆè¡Œï¼ˆåˆ—ï¼‰ã¨å†…éƒ¨æ§‹é€ ã‚’æç”»
    for i, (start_col, end_col) in enumerate(text_columns):
        # è¡Œå…¨ä½“ã®æ ç·š
        color = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)][i % 6]
        cv2.rectangle(result_image, (start_col, 0), (end_col, original_image.shape[0]), color, 2)
        
        # è¡Œç•ªå·ã‚’è¡¨ç¤º
        cv2.putText(result_image, f'Line {i+1}', (start_col, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # è¡Œå†…æ§‹é€ ã®å¯è¦–åŒ–ï¼ˆShoga/Fuji/Hyoshiï¼‰
        col_width = end_col - start_col
        
        # ç°¡æ˜“çš„ãªå†…éƒ¨æ§‹é€ æ¨å®šï¼ˆå®Ÿéš›ã®ãƒ”ãƒ¼ã‚¯æ¤œå‡ºçµæœã‚’ä½¿ç”¨ã™ã¹ãï¼‰
        binary_col = binary[:, start_col:end_col]
        h_proj = np.sum(binary_col, axis=0)
        
        if len(h_proj) > 0:
            from scipy.signal import find_peaks
            from scipy.ndimage import gaussian_filter1d
            smoothed = gaussian_filter1d(h_proj, sigma=2)
            peaks, _ = find_peaks(smoothed, distance=10, height=np.max(smoothed)*0.4)
            
            if len(peaks) > 0:
                shoga_peak = peaks[np.argmax(smoothed[peaks])]
                shoga_center = start_col + shoga_peak
                
                # å†…éƒ¨æ§‹é€ ã®å¢ƒç•Œ
                shoga_left = max(start_col, shoga_center - col_width//6)
                shoga_right = min(end_col, shoga_center + col_width//6)
                fuji_right = shoga_left
                hyoshi_left = shoga_right
                
                # Fujié ˜åŸŸï¼ˆè–„ã„é’ï¼‰
                if fuji_right > start_col:
                    cv2.rectangle(result_image, (start_col, 10), (fuji_right, 40), (255, 200, 100), -1)
                    cv2.putText(result_image, 'F', (start_col + 5, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
                
                # Shogaé ˜åŸŸï¼ˆè–„ã„èµ¤ï¼‰
                cv2.rectangle(result_image, (shoga_left, 10), (shoga_right, 40), (100, 100, 255), -1)
                cv2.putText(result_image, 'S', (shoga_left + 5, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
                
                # Hyoshié ˜åŸŸï¼ˆè–„ã„ç·‘ï¼‰
                if hyoshi_left < end_col:
                    cv2.rectangle(result_image, (hyoshi_left, 10), (end_col, 40), (100, 255, 100), -1)
                    cv2.putText(result_image, 'H', (hyoshi_left + 5, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
    
    # æ–‡å­—é ˜åŸŸã‚’æç”»ï¼ˆShogaã¨Fujiã®ã¿ã€ç•°ãªã‚‹è‰²ã§ï¼‰
    for char_region in character_regions:
        if len(char_region) >= 5:  # æ–°ã—ã„å½¢å¼
            row_start, row_end, col_start, col_end, region_name = char_region
            if region_name == "Shoga":
                cv2.rectangle(result_image, (col_start, row_start), (col_end, row_end), (0, 0, 255), 2)  # èµ¤
            elif region_name == "Fuji":
                cv2.rectangle(result_image, (col_start, row_start), (col_end, row_end), (255, 0, 0), 2)  # é’
        else:  # æ—§å½¢å¼ï¼ˆäº’æ›æ€§ï¼‰
            row_start, row_end, col_start, col_end = char_region
            cv2.rectangle(result_image, (col_start, row_start), (col_end, row_end), (128, 255, 128), 1)
    
    # çµæœã‚’è¡¨ç¤º
    plt.figure(figsize=(20, 12))
    
    # å…ƒç”»åƒ
    plt.subplot(2, 3, 1)
    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
    plt.title('Original Score Image')
    plt.axis('off')
    
    # äºŒå€¤åŒ–ç”»åƒ
    plt.subplot(2, 3, 2)
    plt.imshow(binary, cmap='gray')
    plt.title('Binarized Image')
    plt.axis('off')
    
    # æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
    plt.subplot(2, 3, 3)
    plt.plot(horizontal_projection)
    plt.title('Horizontal Projection\n(Text Density)')
    plt.xlabel('Column (X-axis)')
    plt.ylabel('Character Density')
    plt.grid(True)
    
    # è‡ªå‹•æ¨å®šæƒ…å ±ã®è¡¨ç¤ºï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
    if auto_estimate_info:
        est_peaks = auto_estimate_info['peaks']
        smoothed_proj = auto_estimate_info['smoothed_projection']
        confidence = auto_estimate_info['confidence']
        
        # ã‚¹ãƒ ãƒ¼ã‚ºåŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã‚‚è¡¨ç¤º
        plt.plot(smoothed_proj, 'r--', alpha=0.7, label='Smoothed')
        
        # è‡ªå‹•æ¨å®šã®ãƒ”ãƒ¼ã‚¯ã‚’ãƒãƒ¼ã‚¯
        plt.plot(est_peaks, smoothed_proj[est_peaks], "go", markersize=8, 
                label=f'Auto-Est Peaks ({len(est_peaks)} lines, conf: {confidence:.2f})')
        plt.legend()
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã¯è¿½åŠ æƒ…å ±ã‚’è¡¨ç¤º
    if debug_mode:
        # ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã®è©³ç´°ã‚’è¡¨ç¤º
        from scipy.signal import find_peaks
        from scipy.ndimage import gaussian_filter1d
        smoothed = gaussian_filter1d(horizontal_projection, sigma=5)
        peaks, _ = find_peaks(smoothed, distance=30, height=np.max(smoothed)*0.3)
        plt.plot(peaks, smoothed[peaks], "rx", markersize=8, label='Detected Peaks')
        
        # è‡ªå‹•æ¨å®šã®ãƒ”ãƒ¼ã‚¯ã‚‚è¡¨ç¤º
        if auto_estimate_info:
            est_peaks = auto_estimate_info['peaks']
            plt.plot(est_peaks, smoothed[est_peaks], "go", markersize=10, label=f'Auto-Est Peaks (conf: {auto_estimate_info["confidence"]:.2f})')
        
        plt.legend()
    
    # è¡Œæ¤œå‡ºçµæœ
    line_detection_image = original_image.copy()
    
    # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚‚æç”»
    if title_info and title_info['detected'] and title_info['coordinates']:
        start_col, end_col = title_info['coordinates']
        cv2.rectangle(line_detection_image, (start_col, 0), (end_col, original_image.shape[0]), (0, 215, 255), 4)
    
    for i, (start_col, end_col) in enumerate(text_columns):
        color = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)][i % 6]
        cv2.rectangle(line_detection_image, (start_col, 0), (end_col, original_image.shape[0]), color, 3)
    
    plt.subplot(2, 3, 4)
    plt.imshow(cv2.cvtColor(line_detection_image, cv2.COLOR_BGR2RGB))
    title_text = 'Detected Text Lines\n(Shoga/Fuji/Hyoshi Structure)'
    if title_info and title_info['included_in_analysis']:
        title_text += '\n(Title included)'
    plt.title(title_text)
    plt.axis('off')
    
    # æ–‡å­—é ˜åŸŸæ¤œå‡ºçµæœï¼ˆShogaã¨Fujiã®ã¿ï¼‰
    char_detection_image = original_image.copy()
    for char_region in character_regions:
        if len(char_region) >= 5:  # æ–°ã—ã„å½¢å¼
            row_start, row_end, col_start, col_end, region_name = char_region
            if region_name == "Shoga":
                cv2.rectangle(char_detection_image, (col_start, row_start), (col_end, row_end), (0, 0, 255), 2)
            elif region_name == "Fuji":
                cv2.rectangle(char_detection_image, (col_start, row_start), (col_end, row_end), (255, 0, 0), 2)
        else:
            row_start, row_end, col_start, col_end = char_region
            cv2.rectangle(char_detection_image, (col_start, row_start), (col_end, row_end), (0, 255, 255), 1)
    
    plt.subplot(2, 3, 5)
    plt.imshow(cv2.cvtColor(char_detection_image, cv2.COLOR_BGR2RGB))
    plt.title('Character Regions\n(Shoga: Red, Fuji: Blue)')
    plt.axis('off')
    
    # ç·åˆçµæœ
    plt.subplot(2, 3, 6)
    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))
    plt.title('Complete Layout Analysis\n(F:Fuji, S:Shoga, H:Hyoshi)')
    plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    if debug_mode:
        plt.show()
    else:
        plt.close()  # GUIãªã—ã®å ´åˆã¯ã‚¯ãƒ­ãƒ¼ã‚º

def print_layout_summary(layout_stats, expected_lines=3):
    """æ¥½è­œãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›ï¼ˆShoga/Fuji/Hyoshiæ§‹é€ å¯¾å¿œï¼‰"""
    print("=" * 60)
    print("æ—¥æœ¬ä¼çµ±éŸ³æ¥½æ¥½è­œ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æçµæœ")
    print("=" * 60)
    print(f"æœŸå¾…è¡Œæ•°: {expected_lines}")
    print(f"æ¤œå‡ºã•ã‚ŒãŸè¡Œæ•°ï¼ˆç¸¦æ›¸ãåˆ—æ•°ï¼‰: {layout_stats['num_lines']}")
    print(f"ç·æ–‡å­—é ˜åŸŸæ•°: {layout_stats['num_characters']} (Shoga + Fujiã®ã¿)")
    
    if layout_stats['line_widths']:
        print(f"è¡Œã®å¹³å‡å¹…: {layout_stats['avg_line_width']:.2f}ãƒ”ã‚¯ã‚»ãƒ«")
        print(f"æœ€å¤§è¡Œå¹…: {max(layout_stats['line_widths']):.2f}ãƒ”ã‚¯ã‚»ãƒ«")
        print(f"æœ€å°è¡Œå¹…: {min(layout_stats['line_widths']):.2f}ãƒ”ã‚¯ã‚»ãƒ«")
    
    if layout_stats['chars_per_line']:
        print(f"1è¡Œã‚ãŸã‚Šã®å¹³å‡æ–‡å­—æ•°: {np.mean(layout_stats['chars_per_line']):.1f}")
        print(f"æœ€å¤§æ–‡å­—æ•°/è¡Œ: {max(layout_stats['chars_per_line'])}")
        print(f"æœ€å°æ–‡å­—æ•°/è¡Œ: {min(layout_stats['chars_per_line'])}")
    
    # Shoga/Fujiåˆ†æçµæœ
    if 'shoga_chars_per_line' in layout_stats and 'fuji_chars_per_line' in layout_stats:
        total_shoga = sum(layout_stats['shoga_chars_per_line'])
        total_fuji = sum(layout_stats['fuji_chars_per_line'])
        
        if total_shoga > 0 or total_fuji > 0:
            print(f"\næ¥½è­œæ§‹é€ åˆ†æ:")
            print(f"  ç·Shogaæ–‡å­—æ•°: {total_shoga}")
            print(f"  ç·Fujiæ–‡å­—æ•°: {total_fuji}")
            print(f"  Shoga/Fujiæ¯”ç‡: {total_shoga/(total_shoga+total_fuji)*100:.1f}% / {total_fuji/(total_shoga+total_fuji)*100:.1f}%")
    
    if layout_stats['line_spacing']:
        print(f"è¡Œé–“ã®å¹³å‡é–“éš”: {layout_stats['avg_line_spacing']:.2f}ãƒ”ã‚¯ã‚»ãƒ«")
    
    print("\nå„è¡Œã®è©³ç´°:")
    for i, (width, char_count) in enumerate(zip(layout_stats['line_widths'], layout_stats['chars_per_line'])):
        shoga_count = layout_stats.get('shoga_chars_per_line', [0]*len(layout_stats['line_widths']))[i]
        fuji_count = layout_stats.get('fuji_chars_per_line', [0]*len(layout_stats['line_widths']))[i]
        
        line_detail = f"  è¡Œ {i+1}: å¹…={width}px, ç·æ–‡å­—æ•°={char_count}"
        if shoga_count > 0 or fuji_count > 0:
            line_detail += f" (Shoga:{shoga_count}, Fuji:{fuji_count})"
        print(line_detail)
    
    print("\næ¥½è­œã®ç‰¹å¾´:")
    # æ¥½è­œã®ç‰¹å¾´ã‚’æ¨å®š
    if layout_stats['num_lines'] >= 3:
        print("  - è¤‡æ•°è¡Œæ§‹æˆã®æ¥½è­œã§ã™")
    else:
        print("  - å˜ç´”ãªæ§‹æˆã®æ¥½è­œã§ã™")
    
    if layout_stats['chars_per_line'] and max(layout_stats['chars_per_line']) > 20:
        print("  - é•·ã„æ¥½å¥ã‚’å«ã‚€æ¥½è­œã§ã™")
    
    if layout_stats['line_spacing'] and layout_stats['avg_line_spacing'] > 50:
        print("  - è¡Œé–“ãŒåºƒãã€èª­ã¿ã‚„ã™ã„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ã™")
    elif layout_stats['line_spacing'] and layout_stats['avg_line_spacing'] < 30:
        print("  - å¯†ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®æ¥½è­œã§ã™")
    
    # Shoga/Fujiæ§‹é€ ã®ç‰¹å¾´
    if 'shoga_chars_per_line' in layout_stats and 'fuji_chars_per_line' in layout_stats:
        total_shoga = sum(layout_stats['shoga_chars_per_line'])
        total_fuji = sum(layout_stats['fuji_chars_per_line'])
        
        if total_shoga > total_fuji:
            print("  - Shogaä¸»ä½“ã®æ¥½è­œã§ã™ï¼ˆæ­Œè©ãƒ»éŸ³ç¬¦é‡è¦–ï¼‰")
        elif total_fuji > total_shoga:
            print("  - Fujiä¸»ä½“ã®æ¥½è­œã§ã™ï¼ˆè£…é£¾ãƒ»è£œåŠ©è¨˜å·é‡è¦–ï¼‰")
        else:
            print("  - Shogaãƒ»Fujiãƒãƒ©ãƒ³ã‚¹å‹ã®æ¥½è­œã§ã™")
    
    # èªè­˜ç²¾åº¦ã®è©•ä¾¡
    accuracy = "é«˜" if layout_stats['num_lines'] == expected_lines else "è¦èª¿æ•´"
    print(f"  - èªè­˜ç²¾åº¦: {accuracy}")
    
    if layout_stats['num_lines'] != expected_lines:
        print(f"    æ¨å¥¨: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¾ãŸã¯æœŸå¾…è¡Œæ•°ã®å†æ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")
    
    print("\næ§‹é€ èª¬æ˜:")
    print("  - Shoga: æ­Œè©ãƒ»éŸ³ç¬¦ï¼ˆãƒ”ãƒ¼ã‚¯éƒ¨åˆ†ã€æ–‡å­—èªè­˜å¯¾è±¡ï¼‰")
    print("  - Fuji: è£…é£¾ãƒ»è£œåŠ©è¨˜å·ï¼ˆShogaã®å·¦å´ã€æ–‡å­—èªè­˜å¯¾è±¡ï¼‰")
    print("  - Hyoshi: æ‹å­ãƒ»ãƒªã‚ºãƒ è¨˜å·ï¼ˆShogaã®å³å´ã€æ–‡å­—èªè­˜å¯¾è±¡å¤–ï¼‰")

def estimate_line_count_from_projection(horizontal_projection, image_width):
    """æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ”ãƒ¼ã‚¯æ•°ã‹ã‚‰æ¥½è­œæœ¬æ–‡ã®è¡Œæ•°ã‚’è‡ªå‹•æ¨å®šã™ã‚‹"""
    from scipy.signal import find_peaks
    from scipy.ndimage import gaussian_filter1d
    
    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    smoothed_projection = gaussian_filter1d(horizontal_projection, sigma=5)
    
    # è¤‡æ•°ã®é–¾å€¤ã§è©¦è¡Œã—ã€æœ€é©ãªè¡Œæ•°ã‚’æ±ºå®š
    max_projection = np.max(smoothed_projection)
    
    # ç•°ãªã‚‹é–¾å€¤ã§ã®æ¤œå‡ºçµæœã‚’è©•ä¾¡
    threshold_ratios = [0.15, 0.2, 0.25, 0.3]
    distance_ratios = [0.08, 0.1, 0.12]  # ç”»åƒå¹…ã«å¯¾ã™ã‚‹æ¯”ç‡
    
    candidates = []
    
    for threshold_ratio in threshold_ratios:
        for distance_ratio in distance_ratios:
            threshold_height = max_projection * threshold_ratio
            min_distance = int(image_width * distance_ratio)
            
            peaks, properties = find_peaks(smoothed_projection,
                                         distance=min_distance,
                                         height=threshold_height,
                                         prominence=threshold_height * 0.3)
            
            # ãƒ”ãƒ¼ã‚¯ã®å“è³ªè©•ä¾¡
            if len(peaks) > 0:
                # ãƒ”ãƒ¼ã‚¯é«˜ã•ã®ä¸€è²«æ€§
                peak_heights = smoothed_projection[peaks]
                height_std = np.std(peak_heights) / np.mean(peak_heights) if len(peak_heights) > 1 else 0
                
                # ãƒ”ãƒ¼ã‚¯é–“éš”ã®ä¸€è²«æ€§
                if len(peaks) > 1:
                    intervals = np.diff(np.sort(peaks))
                    interval_std = np.std(intervals) / np.mean(intervals) if np.mean(intervals) > 0 else float('inf')
                else:
                    interval_std = 0
                
                # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
                confidence = height_std + interval_std * 0.5
                
                candidates.append({
                    'count': len(peaks),
                    'confidence': confidence,
                    'peaks': peaks,
                    'threshold': threshold_height,
                    'distance': min_distance,
                    'peak_heights': peak_heights
                })
    
    if not candidates:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éå¸¸ã«ç·©ã„æ¡ä»¶ã§å†è©¦è¡Œ
        threshold_height = max_projection * 0.1
        min_distance = image_width // 10
        peaks, _ = find_peaks(smoothed_projection,
                            distance=min_distance,
                            height=threshold_height)
        estimated_lines = max(1, len(peaks))
        confidence = 0.5  # ä½ã„ä¿¡é ¼åº¦
        print(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¨å®š: {estimated_lines}è¡Œ (ä¿¡é ¼åº¦: ä½)")
        return estimated_lines, confidence, peaks, smoothed_projection
    
    # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ï¼ˆconfidenceãŒæœ€å°ã®ï¼‰å€™è£œã‚’é¸æŠ
    best_candidate = min(candidates, key=lambda x: x['confidence'])
    estimated_lines = best_candidate['count']
    
    # ä¿¡é ¼åº¦ã®èª¿æ•´ï¼ˆ3-6è¡Œã®ç¯„å›²å†…ãªã‚‰ä¿¡é ¼åº¦ã‚’ä¸Šã’ã‚‹ï¼‰
    if 3 <= estimated_lines <= 6:
        confidence = max(0.7, 1.0 - best_candidate['confidence'])
    else:
        confidence = max(0.3, 0.7 - best_candidate['confidence'])
    
    print(f"ğŸ” è¡Œæ•°è‡ªå‹•æ¨å®š:")
    print(f"   æ¨å®šè¡Œæ•°: {estimated_lines}è¡Œ")
    print(f"   ä¿¡é ¼åº¦: {confidence:.2f}")
    print(f"   æ¤œå‡ºãƒ”ãƒ¼ã‚¯æ•°: {len(best_candidate['peaks'])}")
    print(f"   ä½¿ç”¨é–¾å€¤: {best_candidate['threshold']:.1f}")
    
    if confidence < 0.5:
        print(f"âš ï¸ æ³¨æ„: æ¨å®šã®ä¿¡é ¼åº¦ãŒä½ã„ã§ã™ã€‚æ‰‹å‹•ã§è¡Œæ•°ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    
    return estimated_lines, confidence, best_candidate['peaks'], smoothed_projection

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import sys
    import argparse
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š
    parser = argparse.ArgumentParser(description='æ—¥æœ¬ã®ä¼çµ±éŸ³æ¥½æ¥½è­œã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèªè­˜')
    parser.add_argument('--image', '-i', default='å›³1.png', 
                        help='æ¥½è­œç”»åƒã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å›³1.png)')
    parser.add_argument('--lines', '-l', type=int, default=None,
                        help='æœŸå¾…ã™ã‚‹è¡Œæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è‡ªå‹•æ¨å®š)')
    parser.add_argument('--debug', '-d', action='store_true',
                        help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ')
    parser.add_argument('--output', '-o', default='score_layout_analysis.png',
                        help='å‡ºåŠ›ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: score_layout_analysis.png)')
    parser.add_argument('--include-title', '-t', action='store_true',
                        help='ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚‚å«ã‚ã¦è§£æï¼ˆç¸¦æ›¸ãæ¥½è­œã®å®Œå…¨æ§‹é€ ï¼‰')
    parser.add_argument('--manual-lines', '-m', action='store_true',
                        help='è‡ªå‹•æ¨å®šã‚’ç„¡åŠ¹åŒ–ã—ã€æ‰‹å‹•æŒ‡å®šã‚’å¼·åˆ¶')
    
    # å¼•æ•°ãŒå°‘ãªã„å ´åˆã®ç°¡å˜ãªæŒ‡å®šæ–¹æ³•ã‚’ã‚µãƒãƒ¼ãƒˆ
    if len(sys.argv) == 2 and sys.argv[1].isdigit():
        # "python object_detection.py 5" ã®ã‚ˆã†ãªç°¡å˜ãªæŒ‡å®šã‚’ã‚µãƒãƒ¼ãƒˆ
        expected_lines = int(sys.argv[1])
        image_path = "å›³1.png"
        debug_mode = False
        output_file = 'score_layout_analysis.png'
        include_title = False
        auto_estimate = False
        print(f"ç°¡å˜ãƒ¢ãƒ¼ãƒ‰: è¡Œæ•°={expected_lines}, ç”»åƒ=å›³1.png")
    else:
        args = parser.parse_args()
        expected_lines = args.lines
        image_path = args.image
        debug_mode = args.debug
        output_file = args.output
        include_title = args.include_title
        manual_lines = args.manual_lines
    
    if debug_mode:
        print("=== ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ ===")
    
    # è¡Œæ•°ã®æ±ºå®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è‡ªå‹•æ¨å®šã€--manual-linesã§ç„¡åŠ¹åŒ–ï¼‰
    use_auto_estimate = not manual_lines and expected_lines is None
    
    print(f"è¨­å®š:")
    print(f"  ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {image_path}")
    if use_auto_estimate:
        print(f"  è¡Œæ•°: è‡ªå‹•æ¨å®š")
    else:
        print(f"  æœŸå¾…è¡Œæ•°: {expected_lines}")
    print(f"  å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    print(f"  ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {'ON' if debug_mode else 'OFF'}")
    print(f"  ã‚¿ã‚¤ãƒˆãƒ«åˆ—å«ã‚€: {'ON' if include_title else 'OFF'}")
    print(f"  æ¥½è­œæ§‹é€ : ç¸¦æ›¸ãï¼ˆå³â†’å·¦ã€ä¸Šâ†’ä¸‹ï¼‰")
    
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        print(f"æ¥½è­œç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­: {image_path}")
        image = load_image(image_path)
        print(f"ç”»åƒã‚µã‚¤ã‚º: {image.shape}")
        
        # è¡Œæ•°ã®è‡ªå‹•æ¨å®šï¼ˆå¿…è¦ãªå ´åˆï¼‰
        if use_auto_estimate:
            print("æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰è¡Œæ•°ã‚’è‡ªå‹•æ¨å®šä¸­...")
            
            # åˆæœŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å–å¾—ï¼ˆæ¨å®šç”¨ï¼‰
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            denoised = cv2.bilateralFilter(gray, 9, 75, 75)
            binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                           cv2.THRESH_BINARY_INV, 11, 2)
            initial_projection = np.sum(binary, axis=0)
            
            estimated_lines, confidence, detected_peaks, smoothed_proj = estimate_line_count_from_projection(
                initial_projection, image.shape[1])
            
            # æ¨å®šçµæœã‚’ä½¿ç”¨
            expected_lines = estimated_lines
            print(f"âœ… è‡ªå‹•æ¨å®šçµæœ: {expected_lines}è¡Œ")
            print(f"   ä¿¡é ¼åº¦: {confidence:.3f}")
            
            if confidence < 0.5:
                print(f"âš ï¸ æ¨å®šã®ä¿¡é ¼åº¦ãŒä½ã„ãŸã‚ã€æ³¨æ„æ·±ãçµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # ç¸¦æ›¸ããƒ†ã‚­ã‚¹ãƒˆè¡Œæ¤œå‡º
        print(f"ç¸¦æ›¸ããƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’æ¤œå‡ºä¸­ï¼ˆç›®æ¨™è¡Œæ•°: {expected_lines}è¡Œï¼‰...")
        binary, text_columns, horizontal_projection, title_info = detect_text_lines(image, expected_lines, include_title)
        
        # æ–‡å­—é ˜åŸŸæ¤œå‡º
        print("æ–‡å­—é ˜åŸŸã‚’æ¤œå‡ºä¸­...")
        character_regions = detect_character_regions(binary, text_columns)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ åˆ†æ
        print("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ ã‚’åˆ†æä¸­...")
        layout_stats = analyze_layout_structure(text_columns, character_regions, image.shape)
        
        # çµæœã®å¯è¦–åŒ–
        print("çµæœã‚’å¯è¦–åŒ–ä¸­...")
        
        # è‡ªå‹•æ¨å®šã®æƒ…å ±ã‚‚å¯è¦–åŒ–ã«æ¸¡ã™
        auto_estimate_info = None
        if use_auto_estimate:
            auto_estimate_info = {
                'peaks': detected_peaks,
                'smoothed_projection': smoothed_proj,
                'confidence': confidence
            }
        
        visualize_layout_analysis(image, binary, text_columns, character_regions, 
                                 horizontal_projection, title_info, output_file, debug_mode, auto_estimate_info)
        
        # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
        print_layout_summary(layout_stats, expected_lines)
        
        print("æ¥½è­œãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"çµæœç”»åƒãŒ '{output_file}' ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
        # æ¤œå‡ºçµæœã®è©•ä¾¡
        detected_lines = layout_stats['num_lines']
        if use_auto_estimate:
            print(f"ğŸ“Š è‡ªå‹•æ¨å®šè©•ä¾¡:")
            print(f"   æ¨å®šè¡Œæ•°: {expected_lines}")
            print(f"   æ¤œå‡ºè¡Œæ•°: {detected_lines}")
            if detected_lines == expected_lines:
                print(f"âœ… EXCELLENT: è‡ªå‹•æ¨å®šãŒæ­£ç¢ºã§ã—ãŸï¼")
            elif abs(detected_lines - expected_lines) == 1:
                print(f"âœ… GOOD: è‡ªå‹•æ¨å®šãŒã»ã¼æ­£ç¢ºã§ã—ãŸï¼ˆå·®:Â±1è¡Œï¼‰")
            else:
                print(f"âš ï¸ NOTICE: è‡ªå‹•æ¨å®šã«èª¤å·®ãŒã‚ã‚Šã¾ã™ï¼ˆå·®:{abs(detected_lines - expected_lines)}è¡Œï¼‰")
                print(f"   æ‰‹å‹•ã§è¡Œæ•°ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™: --lines {detected_lines}")
        else:
            if detected_lines == expected_lines:
                print(f"âœ… SUCCESS: æœŸå¾…é€šã‚Š{expected_lines}è¡Œæ§‹æˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            else:
                print(f"âš ï¸ NOTICE: {detected_lines}è¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆæœŸå¾…å€¤: {expected_lines}è¡Œï¼‰")
                print("   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚ˆã‚Šç²¾åº¦å‘ä¸ŠãŒå¯èƒ½ã§ã™ã€‚")
            
        if debug_mode:
            print("\n=== ãƒ‡ãƒãƒƒã‚°æƒ…å ± ===")
            print(f"æ¤œå‡ºã•ã‚ŒãŸåˆ—ã®åº§æ¨™:")
            for i, (start, end) in enumerate(text_columns):
                print(f"  è¡Œ{i+1}: Xåº§æ¨™ {start}-{end} (å¹…: {end-start}px)")
            
            if title_info['detected']:
                if title_info['coordinates']:
                    start, end = title_info['coordinates']
                    print(f"  ã‚¿ã‚¤ãƒˆãƒ«åˆ—: Xåº§æ¨™ {start}-{end} (å¹…: {end-start}px)")
                print(f"  ã‚¿ã‚¤ãƒˆãƒ«åˆ—è§£æ: {'å«ã‚€' if title_info['included_in_analysis'] else 'é™¤å¤–'}")
            
            print(f"æ°´å¹³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ:")
            print(f"  æœ€å¤§å€¤: {np.max(horizontal_projection)}")
            print(f"  å¹³å‡å€¤: {np.mean(horizontal_projection):.2f}")
            print(f"  æ¨™æº–åå·®: {np.std(horizontal_projection):.2f}")
        
    except FileNotFoundError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        print("å›³1.pngãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
